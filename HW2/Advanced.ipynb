{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.appName('Graphs-HW2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read lines from the text file\n",
    "pr_sdf = spark.read.load('pr_graph.txt', format=\"text\")\n",
    "\n",
    "#pr_sdf.createOrReplaceTempView('pr_sdf_view')\n",
    "#pr_sdf = spark.sql(\"SELECT CAST(split(value, ' ')[0] AS int) AS from_node, CAST(split(value, ' ')[1] AS int) AS to_node, 'not_important' AS edge_type FROM pr_sdf_view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|from_node|            weight|\n",
      "+---------+------------------+\n",
      "|        1|              0.25|\n",
      "|        2|               0.5|\n",
      "|        3|               1.0|\n",
      "|        4|               1.0|\n",
      "|        5|              0.25|\n",
      "|        6|               1.0|\n",
      "|        7|0.3333333333333333|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helper1 = pr_sdf.groupBy('from_node').count().sort('from_node', ascending=True)\n",
    "\n",
    "divide_by_n = F.udf(lambda x: 1/x, DoubleType())\n",
    "helper1 = helper1.select('from_node', divide_by_n('count'))\n",
    "helper1 = helper1.withColumnRenamed('<lambda>(count)', 'weight')\n",
    "\n",
    "helper1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------------------+\n",
      "|from_node|to_node|            weight|\n",
      "+---------+-------+------------------+\n",
      "|        1|      2|              0.25|\n",
      "|        1|      3|              0.25|\n",
      "|        1|      4|              0.25|\n",
      "|        1|      5|              0.25|\n",
      "|        2|      3|               0.5|\n",
      "|        2|      5|               0.5|\n",
      "|        3|      2|               1.0|\n",
      "|        4|      5|               1.0|\n",
      "|        5|      1|              0.25|\n",
      "|        5|      6|              0.25|\n",
      "|        5|      7|              0.25|\n",
      "|        6|      7|               1.0|\n",
      "|        7|      6|0.3333333333333333|\n",
      "|        7|      2|0.3333333333333333|\n",
      "|        7|      7|0.3333333333333333|\n",
      "|        5|      4|              0.25|\n",
      "+---------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helper2 = pr_sdf.join(helper1, pr_sdf.from_node == helper1.from_node).select(pr_sdf['from_node'], pr_sdf['to_node'], helper1['weight'])\n",
    "helper2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|from_node|           pagerank|\n",
      "+---------+-------------------+\n",
      "|        1|0.14285714285714285|\n",
      "|        2|0.14285714285714285|\n",
      "|        3|0.14285714285714285|\n",
      "|        4|0.14285714285714285|\n",
      "|        5|0.14285714285714285|\n",
      "|        6|0.14285714285714285|\n",
      "|        7|0.14285714285714285|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helper3 = pr_sdf.groupby('from_node').count().sort('from_node', ascending=True)\n",
    "num = helper3.count()\n",
    "\n",
    "helper3 = helper3.withColumn('count', F.lit(1/num))\n",
    "helper3 = helper3.withColumnRenamed('count', 'pagerank')\n",
    "helper3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|from_node|           pagerank|\n",
      "+---------+-------------------+\n",
      "|        1|0.18035714285714285|\n",
      "|        2|0.34226190476190477|\n",
      "|        3|0.24107142857142855|\n",
      "|        4| 0.2107142857142857|\n",
      "|        5|             0.3625|\n",
      "|        6|0.22083333333333333|\n",
      "|        7|0.34226190476190477|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final = helper2.join(helper3, helper2.from_node == helper3.from_node).select(helper2['from_node'], helper2['to_node'], (helper2.weight * helper3.pagerank).alias('product'))\n",
    "final = final.groupby('to_node').agg({'product': 'sum'})\n",
    "final = final.withColumnRenamed('sum(product)', 'pagerank')\n",
    "final = final.withColumnRenamed('to_node', 'from_node').sort('from_node', ascending=True)\n",
    "\n",
    "alpha = 0.85\n",
    "beta = 0.15\n",
    "\n",
    "alpha_beta = F.udf(lambda x: alpha*x+beta, DoubleType())\n",
    "final = final.select('from_node', alpha_beta('pagerank'))\n",
    "final = final.withColumnRenamed('<lambda>(pagerank)', 'pagerank')\n",
    "\n",
    "final.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pagerank(G, num_iter):\n",
    "    \n",
    "    alpha = 0.85\n",
    "    beta = 0.15\n",
    "    G.createOrReplaceTempView('G_view')\n",
    "    G = spark.sql(\"SELECT CAST(split(value, ' ')[0] AS int) AS from_node, CAST(split(value, ' ')[1] AS int) AS to_node, 'not_important' AS edge_type FROM G_view\")\n",
    "\n",
    "\n",
    "    helper1 = G.groupBy('from_node').count().sort('from_node', ascending=True)\n",
    "\n",
    "    divide_by_n = F.udf(lambda x: 1/x, DoubleType())\n",
    "    helper1 = helper1.select('from_node', divide_by_n('count'))\n",
    "    helper1 = helper1.withColumnRenamed('<lambda>(count)', 'weight')\n",
    "    \n",
    "    helper2 = G.join(helper1, G.from_node == helper1.from_node).select(G['from_node'], G['to_node'], helper1['weight'])\n",
    "\n",
    "    helper3 = G.groupby('from_node').count().sort('from_node', ascending=True)\n",
    "    num = helper3.count()\n",
    "    helper3 = helper3.withColumn('count', F.lit(1/num))\n",
    "    helper3 = helper3.withColumnRenamed('count', 'pagerank')\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        final = helper2.join(helper3, helper2.from_node == helper3.from_node).select(helper2['from_node'], helper2['to_node'], (helper2.weight * helper3.pagerank).alias('product'))\n",
    "        final = final.groupby('to_node').agg({'product': 'sum'}).alias('pagerank')\n",
    "        final = final.withColumnRenamed('sum(product)', 'pagerank')\n",
    "        final = final.withColumnRenamed('to_node', 'from_node').sort('from_node', ascending=True)\n",
    "        \n",
    "        alpha_beta = F.udf(lambda x: alpha*x+beta, DoubleType())\n",
    "        final = final.select('from_node', alpha_beta('pagerank'))\n",
    "        final = final.withColumnRenamed('<lambda>(pagerank)', 'pagerank')\n",
    "        \n",
    "        helper3 = final\n",
    "    \n",
    "    \n",
    "    pr_values_sdf = helper3\n",
    "    pr_values_sdf = pr_values_sdf.withColumnRenamed('from_node','node')\n",
    "    \n",
    "    \n",
    "    return pr_values_sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|1 2 0|\n",
      "|1 3 0|\n",
      "|1 4 0|\n",
      "|1 5 0|\n",
      "|2 3 0|\n",
      "|2 5 0|\n",
      "|3 2 0|\n",
      "|4 5 0|\n",
      "|5 1 0|\n",
      "|5 6 0|\n",
      "|5 7 0|\n",
      "|6 7 0|\n",
      "|7 6 0|\n",
      "|7 2 0|\n",
      "|7 7 0|\n",
      "|5 4 0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|node|           pagerank|\n",
      "+----+-------------------+\n",
      "|   1| 0.3056855115440409|\n",
      "|   2|  0.843575161873236|\n",
      "|   3| 0.5262470701160463|\n",
      "|   4|0.36610546184882914|\n",
      "|   5| 0.8147069488207835|\n",
      "|   6| 0.5380753784802238|\n",
      "|   7| 0.9433725923168398|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pagerank(pr_sdf, 5).orderBy(\"node\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
